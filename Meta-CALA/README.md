# Introduction
We propose a novel logit-adjusted loss, termed CALA, which incorporates both the class priors and the ratio of the class-conditional probability densities for the training and test data. Considering the strong performance of meta-learning, we propose a meta-learning-based estimation approach for computing the class-conditional probability density ratio in CALA loss, resulting in a new GLT approach called Meta-CALA. Specifically, the ratio is generated by an adjustment network with a series of neighborhood-related training characteristics as input.

<p align="center">
    <img src="MCALA.jpg" width= "900">
</p>


# Meta-CALA
A code framework that uses pytorch to implement Meta-CALA.

## Environment
- python 3.8
- pytorch 1.9.0
- torchvision 0.10.0

## Running this example
ResNet32 on CIFAR10-LT with an imbalance factor of 10:
```
python train.py --dataset cifar10 --num_classes 10 --imbalanced_factor 10 --nk 40 --tau1 1.5 --tau2 1
```
