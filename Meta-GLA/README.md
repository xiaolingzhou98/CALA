# # Introduction
We propose a novel logit-adjusted loss, termed GLA, which incorporates both the class priors and the ratio of the class-conditional probability densities for the training and test data. Considering the strong performance of meta-learning, we propose a meta-learning-based estimation approach for computing the class-conditional probability density ratio in GLA loss, resulting in a new GLT approach called Meta-GLA. Specifically, the ratio is generated by an adjustment network with a series of neighborhood-related training characteristics as input.

<p align="center">
    <img src="MGLA.png" width= "900">
</p>


# Meta-GLA
A code framework that uses pytorch to implement Meta-GLA.

## Environment
- python 3.8
- pytorch 1.9.0
- torchvision 0.10.0

## Running this example
ResNet32 on CIFAR10-LT with an imbalance factor of 10:
```
python train.py --dataset cifar10 --num_classes 10 --imbalanced_factor 10 --nk 20
```
